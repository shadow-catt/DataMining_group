{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac3fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3724: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.02778571]\n",
      " [23.02778571]\n",
      " [27.96738452]\n",
      " [23.73843277]\n",
      " [23.02778571]\n",
      " [23.73843277]\n",
      " [23.02778571]\n",
      " [23.02778571]\n",
      " [23.73843277]\n",
      " [27.96738452]\n",
      " [27.96738452]\n",
      " [27.96738452]\n",
      " [28.33700277]\n",
      " [28.33700277]\n",
      " [28.83805714]\n",
      " [28.83805714]\n",
      " [29.34661991]\n",
      " [29.34661991]\n",
      " [29.44216537]\n",
      " [29.54303838]\n",
      " [29.54303838]]\n",
      "[25.91 25.86 26.48 26.56 26.19 26.52 25.87 25.51 26.31 26.55 27.1 26.87\n",
      " 27.84 28.25 28.53 28.74 29.12 29.54 29.61 30.3 29.95]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "trees=10 # Number of Trees\n",
    "n_features=7 # Number of features\n",
    "max_depth=20 # Max depth of trees\n",
    "\n",
    "# Import dataset\n",
    "def loadCsvDataSet(fileName=''):\n",
    "    csv_path=os.path.join(fileName,\"海尔智家.csv\")\n",
    "    df=pd.read_csv(csv_path)\n",
    "    #print(df.values)\n",
    "    return df.values\n",
    "\n",
    "# Split dataset into training set and testing set\n",
    "def split_train_test_data(dataSet):\n",
    "    # Select all the lines where the value of feature is larger than value\n",
    "    X_train=dataSet[np.nonzero(dataSet[:,0]<'2021-05-31')[0],:]\n",
    "    X_test=dataSet[np.nonzero(dataSet[:,0]>'2021-05-31')[0],:]\n",
    "    y_train=X_train[:,4]\n",
    "    X_test = X_test[15:]\n",
    "    y_test=X_test[:,4]\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def binSplitDataSet(dataSet,feature,value):\n",
    "    mat0=dataSet[np.nonzero(dataSet[:,feature]>value)[0],:]\n",
    "    mat1=dataSet[np.nonzero(dataSet[:,feature]<value)[0],:]\n",
    "    return mat0,mat1\n",
    "\n",
    "# Calculate variance\n",
    "def regErr(dataSet):\n",
    "    return np.var(dataSet[:,4])*shape(dataSet)[0]\n",
    "\n",
    "# Calculate mean \n",
    "def regLeaf(dataSet):\n",
    "    return np.mean(dataSet[:,4])\n",
    "\n",
    "# Choose the best tree\n",
    "def chooseBestSplit(dataSet, n_features):\n",
    "    # There is no need of cutting branch for random forest\n",
    "    f = dataSet.shape[1]\n",
    "    index = []\n",
    "    bestS = inf\n",
    "    best_feature, bestValue = 0, 0\n",
    "    # Calculate the variance\n",
    "    S = regErr(dataSet) \n",
    "    a = 0\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        # Randomly select n_features data and put them into list index\n",
    "        index.append(np.random.randint(f))\n",
    "    ##print(index)\n",
    "    # Scale the dataset for index time, with feature as property\n",
    "    for feature in index:\n",
    "        # Use set to remove duplicate\n",
    "        # Try each element in the set to find the fittest data for spliting\n",
    "        # Fittest here means the minimize of variance for each parts\n",
    "        for splitVal in set(dataSet[:,feature]):  \n",
    "            # Split \n",
    "            mat0, mat1 = binSplitDataSet(dataSet, feature, splitVal)\n",
    "            try:\n",
    "                # Sum of the variance of two matrix\n",
    "                newS = regErr(mat0) + regErr(mat1) \n",
    "                # If newS is smaller than given bestS, update the data\n",
    "                if bestS > newS:\n",
    "                    bestfeature = feature\n",
    "                    bestValue = splitVal\n",
    "                    bestS = newS\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "            continue\n",
    "    if (shape(mat0)[0] < 10) or (shape(mat1)[0] < 10):\n",
    "    # print(regLeaf(dataSet))\n",
    "        return None, regLeaf(dataSet)\n",
    "    ##print(bestValue)\n",
    "    return bestfeature, bestValue\n",
    "\n",
    "# Use recursion to create tree\n",
    "def createTree(dataSet, n_features, max_depth):\n",
    "    # Use chooseBestSplit function to get bestfeature and bestValue\n",
    "    bestfeature, bestValue = chooseBestSplit(dataSet, n_features)\n",
    "    if bestfeature == None:\n",
    "        # print(bestValue)\n",
    "        return bestValue\n",
    "    max_depth -= 1\n",
    "    # Control the depth of the tree\n",
    "    if max_depth < 0: \n",
    "        # When depth is less then the number announced, return the mean of the dataset\n",
    "        return regLeaf(dataSet)\n",
    "    # Build up tree\n",
    "    retTree = {}\n",
    "    retTree['bestFeature'] = bestfeature\n",
    "    retTree['bestVal'] = bestValue\n",
    "    lSet, rSet = binSplitDataSet(dataSet, bestfeature, bestValue)\n",
    "    retTree['right'] = createTree(rSet, n_features, max_depth)\n",
    "    retTree['left'] = createTree(lSet, n_features, max_depth)\n",
    "    return retTree\n",
    "\n",
    "\n",
    "# Create forest\n",
    "def RandomForest(trees,n_features, max_depth):\n",
    "    Trees = []\n",
    "    # Create n trees to form a forest\n",
    "    for i in range(trees):\n",
    "        Trees.append((createTree(X_train,n_features,max_depth)))\n",
    "    return Trees\n",
    "\n",
    "# 先判断树是不是一个字典，如果不是就到达结束递归的条件，返回tree转化成float的值\n",
    "# 如果是一个字典：继续\n",
    "# 如果data中，tree的bestFeature为下标的数值大于tree的bestVal\n",
    "# 判断左树是否是float类型，是就返回tree的左树\n",
    "# 否则就从左树继续递归\n",
    "# 否则\n",
    "# 判断右树是否是float类型，是就返回tree的右树\n",
    "# 不是float类型就从树的右树进行递归\n",
    "\n",
    "# Use recusion to do the forecast of a single sample\n",
    "def TreeForecast(tree, data):\n",
    "    # Check whether the tree is a dictionary\n",
    "    # If the tree is not a dictionary, the recursion meets the base case\n",
    "    if not isinstance(tree, dict):\n",
    "        # print(type(tree))\n",
    "        # print(float(tree))\n",
    "        return float(tree)\n",
    "    # If value of bestFeature in a data is larger than the value of bestVal in a tree\n",
    "    # Check that whether left tree is float type\n",
    "    if data[tree['bestFeature']] > tree['bestVal']:\n",
    "        # If so, return left tree\n",
    "        if type(tree['left']) == 'float':\n",
    "            return tree['left']\n",
    "        # Else, do the recursion through left tree\n",
    "        else:\n",
    "            return TreeForecast(tree['left'], data)\n",
    "    # If not, do the same procedure to the right tree\n",
    "    else:\n",
    "        if type(tree['right']) == 'float':\n",
    "            return tree['right']\n",
    "        else:\n",
    "            return TreeForecast(tree['right'], data)\n",
    "\n",
    "# Create forecast dataset by using TreeForecast function for many times\n",
    "def createForeCast(tree, dataSet):\n",
    "    n = len(dataSet)\n",
    "    # Using np.mat to transfer the datatype into float\n",
    "    # Create an n*1 array with float datatype\n",
    "    yhat = np.mat(zeros((n, 1)))\n",
    "    # For each element in the array, use TreeForecast to predict\n",
    "    for i in range(n):\n",
    "        yhat[i, 0] = TreeForecast(tree, dataSet[i, :])\n",
    "        # print(yhat[i,0])\n",
    "    return yhat\n",
    "\n",
    "# Use random forest to predict\n",
    "def Predict(Trees,dataSet):\n",
    "    n=len(dataSet)\n",
    "    # Create an n*1 array with float datatype\n",
    "    yhat=np.mat(zeros((n,1)))\n",
    "    # Use every tree in forest to predict the value\n",
    "    # Use yhat to store the predicted value\n",
    "    for tree in Trees: \n",
    "        yhat+=createForeCast(tree,dataSet)#createForecast返回的是一个数组\n",
    "    # Calculate the mean value of each prediction\n",
    "    yhat/=len(Trees)\n",
    "    return yhat\n",
    "\n",
    "\n",
    "loadCsvDataSet=loadCsvDataSet()\n",
    "df = loadCsvDataSet\n",
    "dataSet=loadCsvDataSet\n",
    "X_train,X_test,y_train,y_test=split_train_test_data(dataSet)\n",
    "BestSplit=chooseBestSplit(X_train,n_features)\n",
    "##print(X_test)\n",
    "RF=RandomForest(trees,n_features, max_depth)\n",
    "yhat=Predict(RF,X_test)\n",
    "#yhat=sorted(set(yhat),key=yhat.index) # sorted output\n",
    "print(yhat)\n",
    "print(y_test)\n",
    "#yhat=yhat.reverse()\n",
    "yhat = pd.DataFrame(yhat)\n",
    "yhat=yhat.reindex(index=yhat.index[::-1])\n",
    "yhat.to_csv(r'随机森林-海尔智家.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775a3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "\n",
      "Testing MSE: 0.056\n",
      "\n",
      "Testing MDAE: 0.048\n",
      "\n",
      "Testing MSLE: 0.000\n",
      "\n",
      "Testing MAE: 0.125\n",
      "\n",
      "Testing EVS: 0.998\n",
      "\n",
      "Testing R2: 0.998\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error,median_absolute_error,mean_absolute_error,precision_score,r2_score,explained_variance_score\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv('海尔智家.csv')\n",
    "\n",
    "# Process the data\n",
    "X = df\n",
    "X.drop('交易日期', axis = 1, inplace = True)\n",
    "X = X.values\n",
    "y = df.收盘价\n",
    "y = y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# Do the random forest training\n",
    "print(len(y_test))\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Examine the model\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mdae = median_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "evs=explained_variance_score(y_test, y_pred) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"\\nTesting MSE: {:.3f}\".format(mse))\n",
    "print(\"\\nTesting MDAE: {:.3f}\".format(mdae))\n",
    "print(\"\\nTesting MSLE: {:.3f}\".format(msle))\n",
    "print(\"\\nTesting MAE: {:.3f}\".format(mae))\n",
    "print(\"\\nTesting EVS: {:.3f}\".format(evs))\n",
    "print(\"\\nTesting R2: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d72a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
